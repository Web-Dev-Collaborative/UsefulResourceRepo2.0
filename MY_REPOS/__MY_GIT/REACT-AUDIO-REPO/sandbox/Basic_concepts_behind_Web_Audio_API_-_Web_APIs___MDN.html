<!DOCTYPE html>
<!-- saved from url=(0098)https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API -->
<html lang="en-US" prefix="og: https://ogp.me/ns#" class=""><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="https://developer.mozilla.org/favicon-48x48.97046865.png"><link rel="apple-touch-icon" href="https://developer.mozilla.org/apple-touch-icon.0ea0fa02.png"><meta name="theme-color" content="#ffffff"><link rel="manifest" href="https://developer.mozilla.org/manifest.56b1cedc.json"><script>Array.prototype.flat&&Array.prototype.includes||document.write('<script src="https://polyfill.io/v3/polyfill.min.js?features=Array.prototype.flat%2Ces6"><\/script>')</script><title>Basic concepts behind Web Audio API - Web APIs | MDN</title><link rel="preload" as="font" type="font/woff2" crossorigin="" href="https://developer.mozilla.org/static/media/ZillaSlab-Bold.subset.0beac26b.woff2"><link rel="alternate" title="Basic concepts behind Web Audio API" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API" hreflang="en"><link rel="alternate" title="网页音频接口的基本概念" href="https://developer.mozilla.org/zh-CN/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API" hreflang="zh"><link rel="alternate" title="Basic concepts behind Web Audio API" href="https://developer.mozilla.org/ko/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API" hreflang="ko"><link rel="alternate" title="Basic concepts behind Web Audio API" href="https://developer.mozilla.org/ja/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API" hreflang="ja"><link rel="alternate" title="Les concepts de base de la Web Audio API" href="https://developer.mozilla.org/fr/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API" hreflang="fr"><meta name="description" content="
This article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app. It won&#39;t turn you into a master sound engineer, but it will give you enough background to understand why the Web Audio API works like it does.
This article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app."><meta property="og:url" content="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API"><meta property="og:title" content="Basic concepts behind Web Audio API - Web APIs | MDN"><meta property="og:description" content="
This article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app. It won&#39;t turn you into a master sound engineer, but it will give you enough background to understand why the Web Audio API works like it does.
This article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app."><meta property="og:locale" content="en-US"><meta property="og:image" content="https://developer.mozilla.org/mdn-social-share.2f09512a.png"><meta property="twitter:card" content="summary_large_image"><meta name="robots" content="index, follow"><link rel="canonical" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API"><style media="print">.breadcrumbs-container,.document-toc-container,.language-menu,.language-toggle,.on-github,.page-footer,.page-header-main,nav.sidebar,ul.prev-next{display:none!important}.main-page-content,.main-page-content pre{padding:2px}.main-page-content pre{border-left-width:2px}</style><link href="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/main.4c372865.chunk.css" rel="stylesheet"><script>LUX=(function(){var a=("undefined"!==typeof(LUX)&&"undefined"!==typeof(LUX.gaMarks)?LUX.gaMarks:[]);var d=("undefined"!==typeof(LUX)&&"undefined"!==typeof(LUX.gaMeasures)?LUX.gaMeasures:[]);var j="LUX_start";var k=window.performance;var l=("undefined"!==typeof(LUX)&&LUX.ns?LUX.ns:(Date.now?Date.now():+(new Date())));if(k&&k.timing&&k.timing.navigationStart){l=k.timing.navigationStart}function f(){if(k&&k.now){return k.now()}var o=Date.now?Date.now():+(new Date());return o-l}function b(n){if(k){if(k.mark){return k.mark(n)}else{if(k.webkitMark){return k.webkitMark(n)}}}a.push({name:n,entryType:"mark",startTime:f(),duration:0});return}function m(p,t,n){if("undefined"===typeof(t)&&h(j)){t=j}if(k){if(k.measure){if(t){if(n){return k.measure(p,t,n)}else{return k.measure(p,t)}}else{return k.measure(p)}}else{if(k.webkitMeasure){return k.webkitMeasure(p,t,n)}}}var r=0,o=f();if(t){var s=h(t);if(s){r=s.startTime}else{if(k&&k.timing&&k.timing[t]){r=k.timing[t]-k.timing.navigationStart}else{return}}}if(n){var q=h(n);if(q){o=q.startTime}else{if(k&&k.timing&&k.timing[n]){o=k.timing[n]-k.timing.navigationStart}else{return}}}d.push({name:p,entryType:"measure",startTime:r,duration:(o-r)});return}function h(n){return c(n,g())}function c(p,o){for(i=o.length-1;i>=0;i--){var n=o[i];if(p===n.name){return n}}return undefined}function g(){if(k){if(k.getEntriesByType){return k.getEntriesByType("mark")}else{if(k.webkitGetEntriesByType){return k.webkitGetEntriesByType("mark")}}}return a}return{mark:b,measure:m,gaMarks:a,gaMeasures:d}})();LUX.ns=(Date.now?Date.now():+(new Date()));LUX.ac=[];LUX.cmd=function(a){LUX.ac.push(a)};LUX.init=function(){LUX.cmd(["init"])};LUX.send=function(){LUX.cmd(["send"])};LUX.addData=function(a,b){LUX.cmd(["addData",a,b])};LUX_ae=[];window.addEventListener("error",function(a){LUX_ae.push(a)});LUX_al=[];if("function"===typeof(PerformanceObserver)&&"function"===typeof(PerformanceLongTaskTiming)){var LongTaskObserver=new PerformanceObserver(function(c){var b=c.getEntries();for(var a=0;a<b.length;a++){var d=b[a];LUX_al.push(d)}});try{LongTaskObserver.observe({type:["longtask"]})}catch(e){}};</script><script src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/lux.js.download" async="" defer="" crossorigin="anonymous"></script><script defer="" src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/ga.js.download"></script><script src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/runtime-main.676c6430.js.download" defer=""></script><script src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/2.24ce1d20.chunk.js.download" defer=""></script><script src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/main.5c92da3d.chunk.js.download" defer=""></script><script async="" src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/analytics.js.download"></script><style type="text/css">.fancybox-margin{margin-right:0px;}</style></head><body data-gclp-initialized="true" data-gistbox-initialized="true"><div id="root"><ul id="nav-access" class="a11y-nav"><li><a id="skip-main" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#content">Skip to main content</a></li><li><a id="skip-search" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#main-q">Skip to search</a></li><li><a id="skip-select-language" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#select-language">Skip to select language</a></li></ul><div class="page-wrapper document-page"><header class="page-header"><a href="https://developer.mozilla.org/en-US/" class="logo" aria-label="MDN Web Docs"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 451.74 135" role="img"><g id="Layer_2" data-name="Layer 2"><path class="cls-1" d="M7.14,8.35V119.41H118.19V8.35Zm103.71,56c-.48.92-1,1.79-1.46,2.71a3.44,3.44,0,0,1-3.54,2,2.4,2.4,0,0,0-1.55.5c-1.37.9-2.76,1.79-4.18,2.63a7.33,7.33,0,0,1-6.35.34,29.71,29.71,0,0,0-10.63-2,11.7,11.7,0,0,0-9.46,4.31,14.84,14.84,0,0,0-2.13,4.29c-1.24,3.07-2.3,21.38-2.3,26.05,0,0-17.62-3.42-34.15-20.34l4.31-11.32H25.91l9.76-10.35H18.87l9.77-10.34H12.69L30.45,34A40.9,40.9,0,0,1,50.22,23.17c7.1-1.22,8.93-.53,13.31.77l2.43.73.85.25,3.1.95a12.56,12.56,0,0,0,6.21.09,11.37,11.37,0,0,1,8.25,1,8.24,8.24,0,0,1,4.1,6.22,7.29,7.29,0,0,0,3.61,5.49,59.45,59.45,0,0,0,9.32,4.11c2.27.86,4.54,1.84,6.79,2.72a6.81,6.81,0,0,1,2.86,2.06,4.81,4.81,0,0,1,1.1,2.73c.14,2,.37,4,.47,6h0A15.24,15.24,0,0,1,110.85,64.32Z"></path><path class="cls-1" d="M320.12,39.62a5.42,5.42,0,0,0-4.53,2.13,7.36,7.36,0,0,0-1.7,4.43v2.36a6.28,6.28,0,0,0,1.7,4.46,5.63,5.63,0,0,0,4.3,1.82,5.12,5.12,0,0,0,4.57-2.27A9.7,9.7,0,0,0,326,47a8.11,8.11,0,0,0-1.67-5.52A5.36,5.36,0,0,0,320.12,39.62Z"></path><path class="cls-1" d="M387.38,39.53a5.52,5.52,0,0,0-4.7,2.15,8.8,8.8,0,0,0-1.63,5.49,9.23,9.23,0,0,0,1.58,5.45,5.38,5.38,0,0,0,4.7,2.25,5.61,5.61,0,0,0,4.74-2.2,8.91,8.91,0,0,0,1.68-5.59A8.24,8.24,0,0,0,392,41.56,5.76,5.76,0,0,0,387.38,39.53Z"></path><path class="cls-1" d="M299.47,41.35a4.34,4.34,0,0,0-4-1.92,4.55,4.55,0,0,0-3.89,1.73A8.37,8.37,0,0,0,290,45.33h10.48A6.3,6.3,0,0,0,299.47,41.35Z"></path><path class="cls-1" d="M357.74,30.75H352V54.06h5.72q5.47,0,8.35-3T369,42.41q0-5.43-2.88-8.55T357.74,30.75Z"></path><path class="cls-1" d="M121.55,8.35v70.8h323V8.35ZM163.76,30.8h-4V54h3.68v3.73H152.19V54h3.31V36.79h-.19l-9.63,19.12h-2.12l-10-19.4h-.19V54h3.45v3.73H125.67V54h3.68V30.8h-4V27.07H133l11.66,22.56h.19l11.18-22.56h7.7Zm29.12,22.67q-4.11,4.28-11.38,4.28H167.44V54.06h3.73V30.75h-3.73V27.07h13.83q7.59,0,11.66,4.29a15.4,15.4,0,0,1,4,11A15.33,15.33,0,0,1,192.88,53.47ZM231.77,30.8h-3.68v27h-2.6L208.08,35h-.19V54h4.67v3.73H200.34V54h3.49V30.8h-4V27.07h7.08l16.9,22.09H224V30.8h-4.58V27.07h12.32Zm43.8,27h-3.31l-7.83-23.18h-.19l-7.55,23.18h-3.35L244.56,30.8h-2.65V27.07H253V30.8h-3.87L255,50.71h.23l6.61-19.91H259V27.07h11V30.8h-2.78l6.61,20.1h.23l5.43-20.1h-4.15V27.07h11V30.8h-2.54Zm26.71-1.51a9.66,9.66,0,0,1-6.42,2,10.2,10.2,0,0,1-7.41-2.74c-1.89-1.82-2.83-4.47-2.83-7.93a12.37,12.37,0,0,1,2.64-8.12,9,9,0,0,1,7.32-3.21,8.62,8.62,0,0,1,6.75,2.69,9.65,9.65,0,0,1,2.45,6.52,13.67,13.67,0,0,1-.28,2.69H290q.29,6.71,6.18,6.7a5.2,5.2,0,0,0,3.71-1.18,5.82,5.82,0,0,0,1.67-2.83l3.45.71A7.21,7.21,0,0,1,302.28,56.24Zm25.77-1.63c-1.51,2.4-3.92,3.61-7.22,3.61s-5.84-1.29-7.22-3.87c0,.25-.1.82-.21,1.7s-.19,1.44-.22,1.7H309c.16-1,.31-2,.47-3.07a21.42,21.42,0,0,0,.24-3.16v-23h-3.4V25.27h7.55V40.9a9.76,9.76,0,0,1,2.67-3.28,7.33,7.33,0,0,1,4.74-1.4A8.48,8.48,0,0,1,327.77,39q2.55,2.74,2.55,7.74A14.6,14.6,0,0,1,328.05,54.61Zm41.39-1.14q-4.11,4.28-11.37,4.28H344V54.06h3.73V30.75H344V27.07h13.83q7.59,0,11.66,4.29a15.41,15.41,0,0,1,4.06,11A15.34,15.34,0,0,1,369.44,53.47Zm25.65,1.68a10.53,10.53,0,0,1-7.9,3.07,10,10,0,0,1-7.63-3,10.93,10.93,0,0,1-2.8-7.83,12.13,12.13,0,0,1,2.69-7.93q2.69-3.3,8-3.3t8,3.28a12,12,0,0,1,2.64,7.76A10.86,10.86,0,0,1,395.09,55.15Zm22.61.57c-1.4,1.66-3.63,2.5-6.68,2.5a9.58,9.58,0,0,1-7.15-2.76q-2.72-2.76-2.71-7.91a12.25,12.25,0,0,1,2.69-8,9.17,9.17,0,0,1,7.5-3.28,15,15,0,0,1,3.82.48,10.37,10.37,0,0,1,3.5,1.65l.85,5.47-3.35.38-.76-3.54a8.07,8.07,0,0,0-4.11-1,4.9,4.9,0,0,0-4.39,2.15,9.93,9.93,0,0,0-1.41,5.55A8.9,8.9,0,0,0,407,52.84a5.23,5.23,0,0,0,4.44,2c2.92,0,4.67-1.7,5.23-5.1l3.5.71A10.34,10.34,0,0,1,417.7,55.72Zm20.48.75a11.68,11.68,0,0,1-6.63,1.75,15.52,15.52,0,0,1-8.26-2.08L424,51l3.26.33-.1,2.74a7,7,0,0,0,2.06.66,12.63,12.63,0,0,0,2.19.19,8.68,8.68,0,0,0,3.66-.75,2.5,2.5,0,0,0,1.63-2.36,2.25,2.25,0,0,0-1.32-2.2,12.65,12.65,0,0,0-3.28-1c-1.31-.22-2.61-.49-3.9-.82a7.5,7.5,0,0,1-3.25-1.7,4.67,4.67,0,0,1-1.33-3.66c0-2.36.88-4,2.62-4.91a12,12,0,0,1,5.6-1.37,15,15,0,0,1,4.08.55,16.65,16.65,0,0,1,3.47,1.39l.47,5.1-3.3.37-.48-3.3a9.5,9.5,0,0,0-4.06-.9,5.62,5.62,0,0,0-2.87.66A2.33,2.33,0,0,0,428,42.27a2.13,2.13,0,0,0,1.3,2.07,11.91,11.91,0,0,0,3.21.92,36.69,36.69,0,0,1,3.82.83,7.46,7.46,0,0,1,3.21,1.74,4.9,4.9,0,0,1,1.3,3.73A5.56,5.56,0,0,1,438.18,56.47Z"></path><path class="cls-1" d="M181.17,30.75h-5.71V54.06h5.71q5.47,0,8.36-3t2.88-8.61q0-5.43-2.88-8.55T181.17,30.75Z"></path><path class="cls-1" d="M121.63,119.32V81.74H236.54v37.58ZM153.22,109h-2v-6.85a4.8,4.8,0,0,0-1.58-4,5.57,5.57,0,0,0-3.55-1.26,5,5,0,0,0-4.92,3.26,4.19,4.19,0,0,0-1.88-2.46,5.82,5.82,0,0,0-3-.8,4.89,4.89,0,0,0-4.56,2.56V97.24h-6.28v3.26h2V109h-2v3.23h9.11V109H131.7v-5.25a4.4,4.4,0,0,1,.69-2.56,2.47,2.47,0,0,1,2.21-1q2.57,0,2.56,3.63v8.41h6.29V109h-2v-5.25a4.47,4.47,0,0,1,.67-2.56,2.42,2.42,0,0,1,2.19-1q2.63,0,2.63,3.63v8.41h6.28Zm9.88-12.07q-4,0-6,2.36a8.41,8.41,0,0,0-2,5.66,7.25,7.25,0,0,0,2.17,5.62,8,8,0,0,0,5.65,2,8.54,8.54,0,0,0,5.94-2.11,7.27,7.27,0,0,0,2.34-5.67,8.21,8.21,0,0,0-2-5.51Q167.13,96.94,163.1,96.94ZM163,109.28a3,3,0,0,1-2.63-1.33,5.68,5.68,0,0,1-.9-3.26,5,5,0,0,1,1-3.28,3.23,3.23,0,0,1,2.61-1.18,3.5,3.5,0,0,1,2.59,1.08,4.56,4.56,0,0,1,1.07,3.31,5.21,5.21,0,0,1-1,3.41A3.33,3.33,0,0,1,163,109.28Zm25-2.3-3.39-.29-.7,2.32H179l8.32-9.54L187,97.24H173.81l-.53,5.25,3.16.34.67-2.36h4.65L173.51,110l.44,2.26h13.13Zm7.62-9.74h-4.46v5.39h4.46Zm0,9.61h-4.46v5.39h4.46Zm13.54-17.49h-4.23l-6.48,22.88h4.22Zm8.68,0h-4.23l-6.45,22.88h4.19Zm15,22.51-.07-2.26a1.22,1.22,0,0,1-.56.1c-.69,0-1-.39-1-1.16v-6.49a4.39,4.39,0,0,0-1.8-3.84,7,7,0,0,0-4.16-1.28,14.55,14.55,0,0,0-3.16.3,24.14,24.14,0,0,0-3.29,1.06l-.56,3.46,3.39.4.5-1.69a2.78,2.78,0,0,1,1.08-.37,11.3,11.3,0,0,1,1.25-.07c1.19,0,1.89.37,2.09,1.1a8.55,8.55,0,0,1,.3,2.26v.5a8.91,8.91,0,0,0-1.18-.11c-.41,0-.81,0-1.21,0a12.64,12.64,0,0,0-4.81.88,3.53,3.53,0,0,0-2.18,3.64,3.66,3.66,0,0,0,1.48,3.33,5.63,5.63,0,0,0,3.11,1,4.67,4.67,0,0,0,3-.91,6.78,6.78,0,0,0,1.8-2,3,3,0,0,0,3.33,3A5.54,5.54,0,0,0,232.85,111.87Zm-9.25-2.32a1.69,1.69,0,0,1-1.36-.52,1.81,1.81,0,0,1-.43-1.21,1.67,1.67,0,0,1,.86-1.68,4.63,4.63,0,0,1,2-.42,7.69,7.69,0,0,1,1.07.07l1.06.13a3.58,3.58,0,0,1-1.08,2.74A3.24,3.24,0,0,1,223.6,109.55Z"></path></g></svg></a><button type="button" class="ghost main-menu-toggle" aria-haspopup="true" aria-label="Show Menu"></button><div class="page-header-main "><nav class="main-nav" aria-label="Main menu"><ul class="main-menu"><li class="top-level-entry-container"><button id="technologies-button" type="button" class="top-level-entry" aria-haspopup="menu" aria-expanded="false">Technologies</button><ul class="technologies " role="menu" aria-labelledby="technologies-button"><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web" role="menuitem">Technologies Overview</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/HTML" role="menuitem">HTML</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/CSS" role="menuitem">CSS</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/JavaScript" role="menuitem">JavaScript</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/Guide/Graphics" role="menuitem">Graphics</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/HTTP" role="menuitem">HTTP</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/API" role="menuitem">APIs</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Mozilla/Add-ons/WebExtensions" role="menuitem">Browser Extensions</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/MathML" role="menuitem">MathML</a></li></ul></li><li class="top-level-entry-container"><button id="references-guides-button" type="button" class="top-level-entry" aria-haspopup="menu" aria-expanded="false">References &amp; Guides</button><ul class="references-guides " role="menu" aria-labelledby="references-guides-button"><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Learn" role="menuitem">Learn web development</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/Tutorials" role="menuitem">Tutorials</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/Reference" role="menuitem">References</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/Guide" role="menuitem">Developer Guides</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web/Accessibility" role="menuitem">Accessibility</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Games" role="menuitem">Game development</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/Web" role="menuitem">...more docs</a></li></ul></li><li class="top-level-entry-container"><button id="feedback-button" type="button" class="top-level-entry" aria-haspopup="menu" aria-expanded="false">Feedback</button><ul class="feedback " role="menu" aria-labelledby="feedback-button"><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/MDN/Contribute/Feedback" role="menuitem">Send Feedback</a></li><li role="none"><a tabindex="-1" href="https://developer.mozilla.org/en-US/docs/MDN/Contribute" role="menuitem">Contribute to MDN</a></li><li role="none"><a tabindex="-1" target="_blank" rel="noopener noreferrer" href="https://github.com/mdn/content/issues/new" role="menuitem">Report a content issue 🌐</a></li><li role="none"><a tabindex="-1" target="_blank" rel="noopener noreferrer" href="https://github.com/mdn/yari/issues/new" role="menuitem">Report a platform issue 🌐</a></li></ul></li></ul></nav><div class="header-search"><form action="https://developer.mozilla.org/en-US/search" class="search-form" role="search"><label for="main-q" class="visually-hidden">Search MDN</label><input type="search" name="q" id="main-q" class="search-input-field" placeholder="Search MDN" pattern="(.|\s)*\S(.|\s)*" required=""><input type="submit" class="ghost search-button" aria-label="Search" value=""></form></div><div class="auth-container"><a rel="nofollow" class="signin-link" href="https://developer.mozilla.org/en-US/signin?next=%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWeb_Audio_API%2FBasic_concepts_behind_Web_Audio_API">Sign in</a></div></div></header><div class="breadcrumb-locale-container"><nav class="breadcrumbs-container" aria-label="Breadcrumb navigation"><ol typeof="BreadcrumbList" vocab="https://schema.org/" aria-label="breadcrumbs"><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="https://developer.mozilla.org/en-US/docs/Web"><span property="name">Web technology for developers</span></a><meta property="position" content="1"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb" property="item" typeof="WebPage" href="https://developer.mozilla.org/en-US/docs/Web/API"><span property="name">Web APIs</span></a><meta property="position" content="2"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb-penultimate" property="item" typeof="WebPage" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API"><span property="name">Web Audio API</span></a><meta property="position" content="3"></li><li property="itemListElement" typeof="ListItem"><a class="breadcrumb-current-page" property="item" typeof="WebPage" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API"><span property="name">Basic concepts behind Web Audio API</span></a><meta property="position" content="4"></li></ol></nav><ul class="language-toggle single-option"><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#select-language" class="language-icon"><span class="show-desktop">Change language</span></a></li></ul></div><aside class="document-toc-container"><section class="document-toc"><header><h2>Table of contents</h2><button type="button" class="ghost toc-trigger-mobile" aria-controls="toc-entries" aria-expanded="false">Table of contents</button></header><ul id="toc-entries"><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_graphs">Audio graphs</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_data_whats_in_a_sample">Audio data: what's in a sample</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_buffers_frames_samples_and_channels">Audio buffers: frames, samples and channels</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_channels">Audio channels</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#visualizations">Visualizations</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#spatialisations">Spatialisations</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#fan-in_and_fan-out">Fan-in and Fan-out</a></li></ul></section></aside><main id="content" class="main-content" role="main"><article class="main-page-content" lang="en-US"><h1>Basic concepts behind Web Audio API</h1><div><div class="summary">
<p><span class="seoSummary">This article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app.</span> It won't turn you into a master sound engineer, but it will give you enough background to understand why the Web Audio API works like it does.</p>
</div></div><h2 id="audio_graphs"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_graphs" title="Permalink to Audio graphs">Audio graphs</a></h2><div><p>The <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API">Web Audio API</a> involves handling audio operations inside an <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext">audio context</a>, and has been designed to allow <strong>modular routing</strong>. Basic audio operations are performed with <strong>audio nodes</strong>, which are linked together to form an <strong>audio routing graph</strong>. Several sources — with different types of channel layout — are supported even within a single context. This modular design provides the flexibility to create complex audio functions with dynamic effects.</p>

<p>Audio nodes are linked via their inputs and outputs, forming a chain that starts with one or more sources, goes through one or more nodes, then ends up at a destination. Although, you don't have to provide a destination if you, say, just want to visualize some audio data. A simple, typical workflow for web audio would look something like this:</p>

<ol>
 <li>Create the audio context.</li>
 <li>Inside the context, create sources — such as <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio"><code>&lt;audio&gt;</code></a>, oscillator, or stream.</li>
 <li>Create effects nodes, such as reverb, biquad filter, panner, or compressor.</li>
 <li>Choose the final destination for the audio, such as the user's computer speakers.</li>
 <li>Establish connections from the audio sources through zero or more effects, eventually ending at the chosen destination.</li>
</ol>

<div class="notecard note">
<h4 id="channel_notation">Channel notation</h4>

<p>The number of audio channels available on a signal is frequently presented in a numeric format, such as 2.0 or 5.1. This is called <a title="channel notation" href="https://en.wikipedia.org/wiki/Surround_sound#Channel_notation" class="external" rel=" noopener">channel notation</a>. The first number is the&nbsp;number of full frequency range audio channels that the signal includes. The number after the period indicates the number of those channels which are reserved for low-frequency effect (LFE) outputs; these are often referred to as <strong>subwoofers</strong>.</p>
</div>

<p><img alt="A simple box diagram with an outer box labeled Audio context, and three inner boxes labeled Sources, Effects and Destination. The three inner boxes have arrow between them pointing from left to right, indicating the flow of audio information." src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/webaudioapi_en.svg" style="display: block; margin: 0px auto;" width="643" height="143" loading="lazy"></p>

<p>Each input or output is composed of one or more audio <strong>channels,</strong> which together represent a specific audio layout. Any discrete channel structure is supported, including <em>mono</em>, <em>stereo</em>, <em>quad</em>, <em>5.1</em>, and so on.</p>

<p><img alt="Show the ability of AudioNodes to connect via their inputs and outputs and the channels inside these inputs/outputs." src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/mdn.png" style="display: block; margin: 0px auto;" width="1308" height="750" loading="lazy"></p>

<p>Audio sources can be obtained in a number of ways:</p>

<ul>
 <li>Sound can be generated directly in JavaScript by an audio node (such as an oscillator).</li>
 <li>Created from raw PCM data (the audio context has methods to decode supported audio formats).</li>
 <li>Taken from HTML media elements (such as <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/video"><code>&lt;video&gt;</code></a> or <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/audio"><code>&lt;audio&gt;</code></a>).</li>
 <li>Taken directly from a <a href="https://developer.mozilla.org/en-US/docs/Web/API/WebRTC_API">WebRTC</a> <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStream"><code>MediaStream</code></a> (such as a webcam or microphone).</li>
</ul></div><h2 id="audio_data_whats_in_a_sample"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_data_whats_in_a_sample" title="Permalink to Audio data: what&#39;s in a sample">Audio data: what's in a sample</a></h2><div><p>When an audio signal is processed, <strong>sampling</strong> means the conversion of a <a href="https://en.wikipedia.org/wiki/Continuous_signal" title="Continuous signal" class="external" rel=" noopener">continuous signal</a> to a <a class="mw-redirect external" href="https://en.wikipedia.org/wiki/Discrete_signal" title="Discrete signal" rel=" noopener">discrete signal</a>; or put another way, a continuous sound wave, such as a band playing live, is converted to a sequence of samples (a discrete-time signal) that allow a computer to handle the audio in distinct blocks.</p>

<p>A lot more information can be found on the Wikipedia page <a href="https://en.wikipedia.org/wiki/Sampling_%28signal_processing%29" class="external" rel=" noopener">Sampling (signal processing)</a>.</p></div><h2 id="audio_buffers_frames_samples_and_channels"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_buffers_frames_samples_and_channels" title="Permalink to Audio buffers: frames, samples and channels">Audio buffers: frames, samples and channels</a></h2><div><p>An <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer"><code>AudioBuffer</code></a> takes as its parameters a number of channels (1 for mono, 2 for stereo, etc), a length, meaning the number of sample frames inside the buffer, and a sample rate, which is the number of sample frames played per second.</p>

<p>A sample is a single float32 value that represents the value of the audio stream at each specific point in time, in a specific channel (left or right, if in the case of stereo). A frame, or sample frame, is the set of all values for all channels that will play at a specific point in time: all the samples of all the channels that play at the same time (two for a stereo sound, six for 5.1, etc.)</p>

<p>The sample rate is the number of those samples (or frames, since all samples of a frame play at the same time) that will play in one second, measured in Hz. The higher the sample rate, the better the sound quality.</p>

<p>Let's look at a Mono and a Stereo audio buffer, each is one second long, and playing at 44100Hz:</p>

<ul>
 <li>The Mono buffer will have 44100 samples, and 44100 frames. The <code>length</code> property will be 44100.</li>
 <li>The Stereo buffer will have 88200 samples, but still 44100 frames. The <code>length</code> property will still be 44100 since it's equal to the number of frames.</li>
</ul>

<p><img alt="A diagram showing several frames in an audio buffer in a long line, each one containing two samples, as the buffer has two channels, it is stereo." src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/sampleframe-english.png" width="1245" height="219" loading="lazy"></p>

<p>When a buffer plays, you will hear the left most sample frame, and then the one right next to it, etc. In the case of stereo, you will hear both channels at the same time. Sample frames are very useful, because they are independent of the number of channels, and represent time, in a useful way for doing precise audio manipulation.</p>

<div class="note notecard">
<p><strong>Note</strong>: To get a time in seconds from a frame count, divide the number of frames by the sample rate. To get a number of frames from a number of samples, divide by the channel count.</p>
</div>

<p>Here's a couple of simple examples:</p>

<pre class="brush: js notranslate" data-initialized="true" data-gclp-id="0" style="position: relative;"><code><span class="token keyword">var</span> context <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AudioContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">var</span> buffer <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token number">22050</span><span class="token punctuation">,</span> <span class="token number">44100</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code><div class="open_grepper_editor" title="Edit &amp; Save To Grepper"></div></pre>

<div class="note notecard">
<p><strong>Note</strong>:&nbsp;In&nbsp;<a href="https://en.wikipedia.org/wiki/Digital_audio" title="Digital audio" class="external" rel=" noopener">digital audio</a>,&nbsp;<strong>44,100&nbsp;<a href="https://en.wikipedia.org/wiki/Hertz" class="external" rel=" noopener">Hz</a></strong>&nbsp;(alternately represented as&nbsp;<strong>44.1&nbsp;kHz</strong>) is a common&nbsp;<a href="https://en.wikipedia.org/wiki/Sampling_frequency" title="Sampling frequency" class="external" rel=" noopener">sampling frequency</a>. Why 44.1kHz?&nbsp;<br>
 <br>
 Firstly, because the&nbsp;<a href="https://en.wikipedia.org/wiki/Hearing_range" title="Hearing range" class="external" rel=" noopener">hearing range</a>&nbsp;of human ears is roughly 20&nbsp;Hz to 20,000&nbsp;Hz. Via the&nbsp;<a href="https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem" title="Nyquist–Shannon sampling theorem" class="external" rel=" noopener">Nyquist–Shannon sampling theorem</a>, the sampling frequency must be greater than twice the maximum frequency one wishes to reproduce. Therefore, the sampling rate has to be greater than 40&nbsp;kHz.<br>
 <br>
 Secondly, signals must be&nbsp;<a href="https://en.wikipedia.org/wiki/Low-pass_filter" title="Low-pass filter" class="external" rel=" noopener">low-pass filtered</a>&nbsp;before sampling, otherwise <a href="https://en.wikipedia.org/wiki/Aliasing" class="external" rel=" noopener">aliasing</a>&nbsp;occurs. While an ideal low-pass filter would perfectly pass frequencies below 20&nbsp;kHz (without attenuating them) and perfectly cut off frequencies above 20&nbsp;kHz, in practice a&nbsp;<a href="https://en.wikipedia.org/wiki/Transition_band" title="Transition band" class="external" rel=" noopener">transition band</a>&nbsp;is necessary, where frequencies are partly attenuated. The wider this transition band is, the easier and more economical it is to make an&nbsp;<a href="https://en.wikipedia.org/wiki/Anti-aliasing_filter" title="Anti-aliasing filter" class="external" rel=" noopener">anti-aliasing filter</a>. The 44.1&nbsp;kHz sampling frequency allows for a 2.05&nbsp;kHz transition band.</p>
</div>

<p>If you use this call above, you will get a stereo buffer with two channels, that when played back on an AudioContext running at 44100Hz (very common, most normal sound cards run at this rate), will last for 0.5 seconds: 22050 frames/44100Hz = 0.5 seconds.</p>

<pre class="brush: js notranslate" data-initialized="true" data-gclp-id="1" style="position: relative;"><code><span class="token keyword">var</span> context <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">AudioContext</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token keyword">var</span> buffer <span class="token operator">=</span> context<span class="token punctuation">.</span><span class="token function">createBuffer</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">22050</span><span class="token punctuation">,</span> <span class="token number">22050</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code><div class="open_grepper_editor" title="Edit &amp; Save To Grepper"></div></pre>

<p>If you use this call, you will get a mono buffer with just one channel), that when played back on an AudioContext running at 44100Hz, will be automatically <em>resampled</em> to 44100Hz (and therefore yield 44100 frames), and last for 1.0 second: 44100 frames/44100Hz = 1 second.</p>

<div class="note notecard">
<p><strong>Note</strong>: audio resampling is very similar to image resizing. Say you've got a 16 x 16 image, but you want it to fill a 32x32 area. You resize (or resample) it. The result has less quality (it can be blurry or edgy, depending on the resizing algorithm), but it works, with the resized image taking up less space. Resampled audio is exactly the same: you save space, but in practice you will be unable to properly reproduce high frequency content, or treble sound.</p>
</div></div><h3 id="planar_versus_interleaved_buffers"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#planar_versus_interleaved_buffers" title="Permalink to Planar versus interleaved buffers">Planar versus interleaved buffers</a></h3><div><p>The Web Audio API uses a planar buffer format. The left and right channels are stored like this:</p>

<pre class="notranslate" data-initialized="true" data-gclp-id="2" style="position: relative;">LLLLLLLLLLLLLLLLRRRRRRRRRRRRRRRR (for a buffer of 16 frames)<div class="open_grepper_editor" title="Edit &amp; Save To Grepper"></div></pre>

<p>This is very common in audio processing: it makes it easy to process each channel independently.</p>

<p>The alternative is to use an interleaved buffer format:</p>

<pre class="notranslate" data-initialized="true" data-gclp-id="3" style="position: relative;">LRLRLRLRLRLRLRLRLRLRLRLRLRLRLRLR (for a buffer of 16 frames)<div class="open_grepper_editor" title="Edit &amp; Save To Grepper"></div></pre>

<p>This format is very common for storing and playing back audio without much processing, for example a decoded MP3 stream.<br>
 <br>
 The Web Audio API exposes <strong>only</strong> planar buffers, because it's made for processing. It works with planar, but converts the audio to interleaved when it is sent to the sound card for playback. Conversely, when an MP3 is decoded, it starts off in interleaved format, but is converted to planar for processing.</p></div><h2 id="audio_channels"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#audio_channels" title="Permalink to Audio channels">Audio channels</a></h2><div><p>Different audio buffers contain different numbers of channels: from the more basic mono (only one channel) and stereo (left and right channels), to more complex sets like quad and 5.1, which have different sound samples contained in each channel, leading to a richer sound experience. The channels are usually represented by standard abbreviations detailed in the table below:</p>

<table class="standard-table">
 <tbody>
  <tr>
   <td><em>Mono</em></td>
   <td><code>0: M: mono</code></td>
  </tr>
  <tr>
   <td><em>Stereo</em></td>
   <td><code>0: L: left<br>
    1: R: right</code></td>
  </tr>
  <tr>
   <td><em>Quad</em></td>
   <td><code>0: L: left<br>
    1: R: right<br>
    2: SL: surround left<br>
    3: SR: surround right</code></td>
  </tr>
  <tr>
   <td><em>5.1</em></td>
   <td><code>0: L: left<br>
    1: R: right<br>
    2: C: center<br>
    3: LFE: subwoofer<br>
    4: SL: surround left<br>
    5: SR: surround right</code></td>
  </tr>
 </tbody>
</table></div><h3 id="up-mixing_and_down-mixing"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#up-mixing_and_down-mixing" title="Permalink to Up-mixing and down-mixing">Up-mixing and down-mixing</a></h3><div><p>When the number of channels doesn't match between an input and an output, up- or down-mixing happens according the following rules. This can be somewhat controlled by setting the <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioNode/channelInterpretation"><code>AudioNode.channelInterpretation</code></a> property to <code>speakers</code> or <code>discrete</code>:</p>

<table class="standard-table">
 <thead>
  <tr>
   <th scope="row">Interpretation</th>
   <th scope="col">Input channels</th>
   <th scope="col">Output channels</th>
   <th scope="col">Mixing rules</th>
  </tr>
 </thead>
 <tbody>
  <tr>
   <th rowspan="13" scope="row"><code>speakers</code></th>
   <td><code>1</code> <em>(Mono)</em></td>
   <td><code>2</code> <em>(Stereo)</em></td>
   <td><em>Up-mix from mono to stereo</em>.<br>
    The <code>M</code> input channel is used for both output channels (<code>L</code> and <code>R</code>).<br>
    <code>output.L = input.M<br>
    output.R = input.M</code></td>
  </tr>
  <tr>
   <td><code>1</code> <em>(Mono)</em></td>
   <td><code>4</code> <em>(Quad)</em></td>
   <td><em>Up-mix from mono to quad.</em><br>
    The <code>M</code> input channel is used for non-surround output channels (<code>L</code> and <code>R</code>). Surround output channels (<code>SL</code> and <code>SR</code>) are silent.<br>
    <code>output.L = input.M<br>
    output.R = input.M<br>
    output.SL = 0<br>
    output.SR = 0</code></td>
  </tr>
  <tr>
   <td><code>1</code> <em>(Mono)</em></td>
   <td><code>6</code> <em>(5.1)</em></td>
   <td><em>Up-mix from mono to 5.1.</em><br>
    The <code>M</code> input channel is used for the center output channel (<code>C</code>). All the others (<code>L</code>, <code>R</code>, <code>LFE</code>, <code>SL</code>, and <code>SR</code>) are silent.<br>
    <code>output.L = 0<br>
    output.R = 0</code><br>
    <code>output.C = input.M<br>
    output.LFE = 0<br>
    output.SL = 0<br>
    output.SR = 0</code></td>
  </tr>
  <tr>
   <td><code>2</code> <em>(Stereo)</em></td>
   <td><code>1</code> <em>(Mono)</em></td>
   <td><em>Down-mix from stereo to mono</em>.<br>
    Both input channels (<code>L</code> and <code>R</code>) are equally combined to produce the unique output channel (<code>M</code>).<br>
    <code>output.M = 0.5 * (input.L + input.R)</code></td>
  </tr>
  <tr>
   <td><code>2</code> <em>(Stereo)</em></td>
   <td><code>4</code> <em>(Quad)</em></td>
   <td><em>Up-mix from stereo to quad.</em><br>
    The <code>L</code> and <code>R </code>input channels are used for their non-surround respective output channels (<code>L</code> and <code>R</code>). Surround output channels (<code>SL</code> and <code>SR</code>) are silent.<br>
    <code>output.L = input.L<br>
    output.R = input.R<br>
    output.SL = 0<br>
    output.SR = 0</code></td>
  </tr>
  <tr>
   <td><code>2</code> <em>(Stereo)</em></td>
   <td><code>6</code> <em>(5.1)</em></td>
   <td><em>Up-mix from stereo to 5.1.</em><br>
    The <code>L</code> and <code>R </code>input channels are used for their non-surround respective output channels (<code>L</code> and <code>R</code>). Surround output channels (<code>SL</code> and <code>SR</code>), as well as the center (<code>C</code>) and subwoofer (<code>LFE</code>) channels, are left silent.<br>
    <code>output.L = input.L<br>
    output.R = input.R<br>
    output.C = 0<br>
    output.LFE = 0<br>
    output.SL = 0<br>
    output.SR = 0</code></td>
  </tr>
  <tr>
   <td><code>4</code> <em>(Quad)</em></td>
   <td><code>1</code> <em>(Mono)</em></td>
   <td><em>Down-mix from quad to mono</em>.<br>
    All four input channels (<code>L</code>, <code>R</code>, <code>SL</code>, and <code>SR</code>) are equally combined to produce the unique output channel (<code>M</code>).<br>
    <code>output.M = 0.25 * (input.L + input.R + </code><code>input.SL + input.SR</code><code>)</code></td>
  </tr>
  <tr>
   <td><code>4</code> <em>(Quad)</em></td>
   <td><code>2</code> <em>(Stereo)</em></td>
   <td><em>Down-mix from quad to stereo</em>.<br>
    Both left input channels (<code>L</code> and <code>SL</code>) are equally combined to produce the unique left output channel (<code>L</code>). And similarly, both right input channels (<code>R</code> and <code>SR</code>) are equally combined to produce the unique right output channel (<code>R</code>).<br>
    <code>output.L = 0.5 * (input.L + input.SL</code><code>)</code><br>
    <code>output.R = 0.5 * (input.R + input.SR</code><code>)</code></td>
  </tr>
  <tr>
   <td><code>4</code> <em>(Quad)</em></td>
   <td><code>6</code> <em>(5.1)</em></td>
   <td><em>Up-mix from quad to 5.1.</em><br>
    The <code>L</code>, <code>R</code>, <code>SL</code>, and <code>SR</code> input channels are used for their respective output channels (<code>L</code> and <code>R</code>). Center (<code>C</code>) and subwoofer (<code>LFE</code>) channels are left silent.<br>
    <code>output.L = input.L<br>
    output.R = input.R<br>
    output.C = 0<br>
    output.LFE = 0<br>
    output.SL = input.SL<br>
    output.SR = input.SR</code></td>
  </tr>
  <tr>
   <td><code>6</code> <em>(5.1)</em></td>
   <td><code>1</code> <em>(Mono)</em></td>
   <td><em>Down-mix from 5.1 to mono.</em><br>
    The left (<code>L</code> and <code>SL</code>), right (<code>R</code> and <code>SR</code>) and central channels are all mixed together. The surround channels are slightly attenuated and the regular lateral channels are power-compensated to make them count as a single channel by multiplying by <code>√2/2</code>. The subwoofer (<code>LFE</code>) channel is lost.<br>
    <code>output.M = 0.7071 * (input.L + input.R) + input.C + 0.5 * (input.SL + input.SR)</code></td>
  </tr>
  <tr>
   <td><code>6</code> <em>(5.1)</em></td>
   <td><code>2</code> <em>(Stereo)</em></td>
   <td><em>Down-mix from 5.1 to stereo.</em><br>
    The central channel (<code>C</code>) is summed with each lateral surround channel (<code>SL</code> or <code>SR</code>) and mixed to each lateral channel. As it is mixed down to two channels, it is mixed at a lower power: in each case it is multiplied by <code>√2/2</code>. The subwoofer (<code>LFE</code>) channel is lost.<br>
    <code>output.L = input.L + 0.7071 * (input.C + input.SL)<br>
    output.R = input.R </code><code>+ 0.7071 * (input.C + input.SR)</code></td>
  </tr>
  <tr>
   <td><code>6</code> <em>(5.1)</em></td>
   <td><code>4</code> <em>(Quad)</em></td>
   <td><em>Down-mix from 5.1 to quad.</em><br>
    The central (<code>C</code>) is mixed with the lateral non-surround channels (<code>L</code> and <code>R</code>). As it is mixed down to two channels, it is mixed at a lower power: in each case it is multiplied by <code>√2/2</code>. The surround channels are passed unchanged. The subwoofer (<code>LFE</code>) channel is lost.<br>
    <code>output.L = input.L + 0.7071 * input.C<br>
    output.R = input.R + 0.7071 * input.C<br>
    output.SL = input.SL<br>
    output.SR = input.SR</code></td>
  </tr>
  <tr>
   <td colspan="2">Other, non-standard layouts</td>
   <td>Non-standard channel layouts are handled as if <code>channelInterpretation</code> is set to <code>discrete</code>.<br>
    The specification explicitly allows the future definition of new speaker layouts. This fallback is therefore not future proof as the behavior of the browsers for a specific number of channels may change in the future.</td>
  </tr>
  <tr>
   <th rowspan="2" scope="row"><code>discrete</code></th>
   <td>any (<code>x</code>)</td>
   <td>any (<code>y</code>) where <code>x&lt;y</code></td>
   <td><em>Up-mix discrete channels.</em><br>
    Fill each output channel with its input counterpart, that is the input channel with the same index. Channels with no corresponding input channels are left silent.</td>
  </tr>
  <tr>
   <td>any (<code>x</code>)</td>
   <td>any (<code>y</code>) where <code>x&gt;y</code></td>
   <td><em>Down-mix discrete channels.</em><br>
    Fill each output channel with its input counterpart, that is the input channel with the same index. Input channels with no corresponding output channels are dropped.</td>
  </tr>
 </tbody>
</table></div><h2 id="visualizations"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#visualizations" title="Permalink to Visualizations">Visualizations</a></h2><div><p>In general, audio visualizations are achieved by accessing an output of audio data over time, usually gain or frequency data, and then using a graphical technology to turn that into a visual output, such as a graph. The Web Audio API has an <a href="https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode"><code>AnalyserNode</code></a> available that doesn't alter the audio signal passing through it. Instead it outputs audio data that can be passed to a visualization technology such as <a href="https://developer.mozilla.org/en-US/docs/Web/HTML/Element/canvas"><code>&lt;canvas&gt;</code></a>.</p>

<p><img alt="Without modifying the audio stream, the node allows to get the frequency and time-domain data associated to it, using a FFT." src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/fttaudiodata_en.svg" width="693" height="206" loading="lazy"></p>

<p>You can grab data using the following methods:</p>

<dl>
 <dt><a href="https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getFloatFrequencyData"><code>AnalyserNode.getFloatFrequencyData()</code></a></dt>
 <dd>Copies the current frequency data into a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array"><code>Float32Array</code></a> array passed into it.</dd>
 <dt><a href="https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData"><code>AnalyserNode.getByteFrequencyData()</code></a></dt>
 <dd>Copies the current frequency data into a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array"><code>Uint8Array</code></a> (unsigned byte array) passed into it.</dd>
 <dt><a href="https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getFloatTimeDomainData"><code>AnalyserNode.getFloatTimeDomainData()</code></a></dt>
 <dd>Copies the current waveform, or time-domain, data into a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array"><code>Float32Array</code></a> array passed into it.</dd>
 <dt><a href="https://developer.mozilla.org/en-US/docs/Web/API/AnalyserNode/getByteTimeDomainData"><code>AnalyserNode.getByteTimeDomainData()</code></a></dt>
 <dd>Copies the current waveform, or time-domain, data into a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array"><code>Uint8Array</code></a> (unsigned byte array) passed into it.</dd>
</dl>

<div class="note notecard">
<p><strong>Note</strong>: For more information, see our <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API">Visualizations with Web Audio API</a> article.</p>
</div></div><h2 id="spatialisations"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#spatialisations" title="Permalink to Spatialisations">Spatialisations</a></h2><div><div>
<p>An audio spatialisation (handled by the <a href="https://developer.mozilla.org/en-US/docs/Web/API/PannerNode"><code>PannerNode</code></a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioListener"><code>AudioListener</code></a> nodes in the Web Audio API) allows us to model the position and behavior of an audio signal at a certain point in space, and the listener hearing that audio.</p>

<p>The panner's position is described with right-hand Cartesian coordinates; its movement using a velocity vector, necessary for creating Doppler effects, and its directionality using a directionality cone.The cone can be very large, e.g. for omnidirectional sources.</p>
</div>

<p><img alt="The PannerNode brings a spatial position and velocity and a directionality for a given signal." src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/pannernode_en.svg" width="799" height="340" loading="lazy"></p>

<div>
<p>The listener's position is described using right-hand Cartesian coordinates; its movement using a velocity vector and the direction the listener's head is pointing using two direction vectors: up and front. These respectively define the direction of the top of the listener's head, and the direction the listener's nose is pointing, and are at right angles to one another.</p>
</div>

<p><img alt="We see the position, up and front vectors of an AudioListener, with the up and front vectors at 90° from the other." src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/webaudiolistenerreduced.png" style="display: block; margin: 0 auto;" width="634" height="250" loading="lazy"></p>

<div class="note notecard">
<p><strong>Note</strong>: For more information, see our <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics">Web audio spatialization basics</a> article.</p>
</div></div><h2 id="fan-in_and_fan-out"><a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API#fan-in_and_fan-out" title="Permalink to Fan-in and Fan-out">Fan-in and Fan-out</a></h2><div><p>In audio terms, <strong>fan-in</strong> describes the process by which a <a href="https://developer.mozilla.org/en-US/docs/Web/API/ChannelMergerNode"><code>ChannelMergerNode</code></a> takes a series of mono input sources and outputs a single multi-channel signal:</p>

<p><img alt="" src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/fanin.svg" width="325" height="258" loading="lazy"></p>

<p><strong>Fan-out</strong> describes the opposite process, whereby a <a href="https://developer.mozilla.org/en-US/docs/Web/API/ChannelSplitterNode"><code>ChannelSplitterNode</code></a> takes a multi-channel input source and outputs multiple mono output signals:</p>

<p><img alt="" src="./Basic concepts behind Web Audio API - Web APIs _ MDN_files/fanout.svg" width="325" height="258" loading="lazy"></p></div></article><aside class="metadata"><div class="metadata-content-container"><div id="on-github" class="on-github"><h4>Found a problem with this page?</h4><ul><li><a href="https://github.com/mdn/content/blob/main/files/en-us/web/api/web_audio_api/basic_concepts_behind_web_audio_api/index.html" title="Folder: en-us/web/api/web_audio_api/basic_concepts_behind_web_audio_api (Opens in a new tab)" target="_blank" rel="noopener noreferrer">Source on <b>GitHub</b></a></li><li><a href="https://github.com/mdn/content/issues/new?body=MDN+URL%3A+https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWeb_Audio_API%2FBasic_concepts_behind_Web_Audio_API%0A%0A%23%23%23%23+What+information+was+incorrect%2C+unhelpful%2C+or+incomplete%3F%0A%0A%0A%23%23%23%23+Specific+section+or+headline%3F%0A%0A%0A%23%23%23%23+What+did+you+expect+to+see%3F%0A%0A%0A%23%23%23%23+Did+you+test+this%3F+If+so%2C+how%3F%0A%0A%0A%3C%21--+Do+not+make+changes+below+this+line+--%3E%0A%3Cdetails%3E%0A%3Csummary%3EMDN+Content+page+report+details%3C%2Fsummary%3E%0A%0A*+Folder%3A+%60en-us%2Fweb%2Fapi%2Fweb_audio_api%2Fbasic_concepts_behind_web_audio_api%60%0A*+MDN+URL%3A+https%3A%2F%2Fdeveloper.mozilla.org%2Fen-US%2Fdocs%2FWeb%2FAPI%2FWeb_Audio_API%2FBasic_concepts_behind_Web_Audio_API%0A*+GitHub+URL%3A+https%3A%2F%2Fgithub.com%2Fmdn%2Fcontent%2Fblob%2Fmain%2Ffiles%2Fen-us%2Fweb%2Fapi%2Fweb_audio_api%2Fbasic_concepts_behind_web_audio_api%2Findex.html%0A*+Last+commit%3A+https%3A%2F%2Fgithub.com%2Fmdn%2Fcontent%2Fcommit%2Fd9c4fbb8634df27ca295ec25089a5f7302afb3bf%0A*+Document+last+modified%3A+2021-05-28T04%3A40%3A33.000Z%0A%0A%3C%2Fdetails%3E&amp;title=Issue+with+%22Basic+concepts+behind+Web+Audio+API%22%3A+%28short+summary+here+please%29&amp;labels=Content%3AWebAPI%2Cneeds-triage" title="This will take you to https://github.com/mdn/content to file a new issue" target="_blank" rel="noopener noreferrer">Report a problem with this content on <b>GitHub</b></a></li><li>Want to fix the problem yourself? See <a href="https://github.com/mdn/content/blob/main/README.md" target="_blank" rel="noopener noreferrer">our Contribution guide</a>.</li></ul></div><p class="last-modified-date"><b>Last modified:</b> <time datetime="2021-05-28T04:40:33.000Z">May 28, 2021</time>, <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/contributors.txt">by MDN contributors</a></p><form class="language-menu"><fieldset id="select-language"><legend>Change your language</legend><label for="language-selector" class="visually-hidden">Select your preferred language</label> <select id="language-selector" name="language"><option value="en-US">English (US)</option><option value="fr">Français</option><option value="ja">日本語</option><option value="ko">한국어</option><option value="zh-CN">中文 (简体)</option></select> <button type="submit" class="button minimal">Change language</button></fieldset></form></div></aside></main></div><footer id="nav-footer" class="page-footer"><div class="content-container"><div class="page-footer-logo"><a href="https://developer.mozilla.org/en-US/" class="logo" aria-label="MDN Web Docs"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 451.74 135" role="img" fill="#fff"><g id="Layer_2" data-name="Layer 2"><path class="cls-1" d="M7.14,8.35V119.41H118.19V8.35Zm103.71,56c-.48.92-1,1.79-1.46,2.71a3.44,3.44,0,0,1-3.54,2,2.4,2.4,0,0,0-1.55.5c-1.37.9-2.76,1.79-4.18,2.63a7.33,7.33,0,0,1-6.35.34,29.71,29.71,0,0,0-10.63-2,11.7,11.7,0,0,0-9.46,4.31,14.84,14.84,0,0,0-2.13,4.29c-1.24,3.07-2.3,21.38-2.3,26.05,0,0-17.62-3.42-34.15-20.34l4.31-11.32H25.91l9.76-10.35H18.87l9.77-10.34H12.69L30.45,34A40.9,40.9,0,0,1,50.22,23.17c7.1-1.22,8.93-.53,13.31.77l2.43.73.85.25,3.1.95a12.56,12.56,0,0,0,6.21.09,11.37,11.37,0,0,1,8.25,1,8.24,8.24,0,0,1,4.1,6.22,7.29,7.29,0,0,0,3.61,5.49,59.45,59.45,0,0,0,9.32,4.11c2.27.86,4.54,1.84,6.79,2.72a6.81,6.81,0,0,1,2.86,2.06,4.81,4.81,0,0,1,1.1,2.73c.14,2,.37,4,.47,6h0A15.24,15.24,0,0,1,110.85,64.32Z"></path><path class="cls-1" d="M320.12,39.62a5.42,5.42,0,0,0-4.53,2.13,7.36,7.36,0,0,0-1.7,4.43v2.36a6.28,6.28,0,0,0,1.7,4.46,5.63,5.63,0,0,0,4.3,1.82,5.12,5.12,0,0,0,4.57-2.27A9.7,9.7,0,0,0,326,47a8.11,8.11,0,0,0-1.67-5.52A5.36,5.36,0,0,0,320.12,39.62Z"></path><path class="cls-1" d="M387.38,39.53a5.52,5.52,0,0,0-4.7,2.15,8.8,8.8,0,0,0-1.63,5.49,9.23,9.23,0,0,0,1.58,5.45,5.38,5.38,0,0,0,4.7,2.25,5.61,5.61,0,0,0,4.74-2.2,8.91,8.91,0,0,0,1.68-5.59A8.24,8.24,0,0,0,392,41.56,5.76,5.76,0,0,0,387.38,39.53Z"></path><path class="cls-1" d="M299.47,41.35a4.34,4.34,0,0,0-4-1.92,4.55,4.55,0,0,0-3.89,1.73A8.37,8.37,0,0,0,290,45.33h10.48A6.3,6.3,0,0,0,299.47,41.35Z"></path><path class="cls-1" d="M357.74,30.75H352V54.06h5.72q5.47,0,8.35-3T369,42.41q0-5.43-2.88-8.55T357.74,30.75Z"></path><path class="cls-1" d="M121.55,8.35v70.8h323V8.35ZM163.76,30.8h-4V54h3.68v3.73H152.19V54h3.31V36.79h-.19l-9.63,19.12h-2.12l-10-19.4h-.19V54h3.45v3.73H125.67V54h3.68V30.8h-4V27.07H133l11.66,22.56h.19l11.18-22.56h7.7Zm29.12,22.67q-4.11,4.28-11.38,4.28H167.44V54.06h3.73V30.75h-3.73V27.07h13.83q7.59,0,11.66,4.29a15.4,15.4,0,0,1,4,11A15.33,15.33,0,0,1,192.88,53.47ZM231.77,30.8h-3.68v27h-2.6L208.08,35h-.19V54h4.67v3.73H200.34V54h3.49V30.8h-4V27.07h7.08l16.9,22.09H224V30.8h-4.58V27.07h12.32Zm43.8,27h-3.31l-7.83-23.18h-.19l-7.55,23.18h-3.35L244.56,30.8h-2.65V27.07H253V30.8h-3.87L255,50.71h.23l6.61-19.91H259V27.07h11V30.8h-2.78l6.61,20.1h.23l5.43-20.1h-4.15V27.07h11V30.8h-2.54Zm26.71-1.51a9.66,9.66,0,0,1-6.42,2,10.2,10.2,0,0,1-7.41-2.74c-1.89-1.82-2.83-4.47-2.83-7.93a12.37,12.37,0,0,1,2.64-8.12,9,9,0,0,1,7.32-3.21,8.62,8.62,0,0,1,6.75,2.69,9.65,9.65,0,0,1,2.45,6.52,13.67,13.67,0,0,1-.28,2.69H290q.29,6.71,6.18,6.7a5.2,5.2,0,0,0,3.71-1.18,5.82,5.82,0,0,0,1.67-2.83l3.45.71A7.21,7.21,0,0,1,302.28,56.24Zm25.77-1.63c-1.51,2.4-3.92,3.61-7.22,3.61s-5.84-1.29-7.22-3.87c0,.25-.1.82-.21,1.7s-.19,1.44-.22,1.7H309c.16-1,.31-2,.47-3.07a21.42,21.42,0,0,0,.24-3.16v-23h-3.4V25.27h7.55V40.9a9.76,9.76,0,0,1,2.67-3.28,7.33,7.33,0,0,1,4.74-1.4A8.48,8.48,0,0,1,327.77,39q2.55,2.74,2.55,7.74A14.6,14.6,0,0,1,328.05,54.61Zm41.39-1.14q-4.11,4.28-11.37,4.28H344V54.06h3.73V30.75H344V27.07h13.83q7.59,0,11.66,4.29a15.41,15.41,0,0,1,4.06,11A15.34,15.34,0,0,1,369.44,53.47Zm25.65,1.68a10.53,10.53,0,0,1-7.9,3.07,10,10,0,0,1-7.63-3,10.93,10.93,0,0,1-2.8-7.83,12.13,12.13,0,0,1,2.69-7.93q2.69-3.3,8-3.3t8,3.28a12,12,0,0,1,2.64,7.76A10.86,10.86,0,0,1,395.09,55.15Zm22.61.57c-1.4,1.66-3.63,2.5-6.68,2.5a9.58,9.58,0,0,1-7.15-2.76q-2.72-2.76-2.71-7.91a12.25,12.25,0,0,1,2.69-8,9.17,9.17,0,0,1,7.5-3.28,15,15,0,0,1,3.82.48,10.37,10.37,0,0,1,3.5,1.65l.85,5.47-3.35.38-.76-3.54a8.07,8.07,0,0,0-4.11-1,4.9,4.9,0,0,0-4.39,2.15,9.93,9.93,0,0,0-1.41,5.55A8.9,8.9,0,0,0,407,52.84a5.23,5.23,0,0,0,4.44,2c2.92,0,4.67-1.7,5.23-5.1l3.5.71A10.34,10.34,0,0,1,417.7,55.72Zm20.48.75a11.68,11.68,0,0,1-6.63,1.75,15.52,15.52,0,0,1-8.26-2.08L424,51l3.26.33-.1,2.74a7,7,0,0,0,2.06.66,12.63,12.63,0,0,0,2.19.19,8.68,8.68,0,0,0,3.66-.75,2.5,2.5,0,0,0,1.63-2.36,2.25,2.25,0,0,0-1.32-2.2,12.65,12.65,0,0,0-3.28-1c-1.31-.22-2.61-.49-3.9-.82a7.5,7.5,0,0,1-3.25-1.7,4.67,4.67,0,0,1-1.33-3.66c0-2.36.88-4,2.62-4.91a12,12,0,0,1,5.6-1.37,15,15,0,0,1,4.08.55,16.65,16.65,0,0,1,3.47,1.39l.47,5.1-3.3.37-.48-3.3a9.5,9.5,0,0,0-4.06-.9,5.62,5.62,0,0,0-2.87.66A2.33,2.33,0,0,0,428,42.27a2.13,2.13,0,0,0,1.3,2.07,11.91,11.91,0,0,0,3.21.92,36.69,36.69,0,0,1,3.82.83,7.46,7.46,0,0,1,3.21,1.74,4.9,4.9,0,0,1,1.3,3.73A5.56,5.56,0,0,1,438.18,56.47Z"></path><path class="cls-1" d="M181.17,30.75h-5.71V54.06h5.71q5.47,0,8.36-3t2.88-8.61q0-5.43-2.88-8.55T181.17,30.75Z"></path><path class="cls-1" d="M121.63,119.32V81.74H236.54v37.58ZM153.22,109h-2v-6.85a4.8,4.8,0,0,0-1.58-4,5.57,5.57,0,0,0-3.55-1.26,5,5,0,0,0-4.92,3.26,4.19,4.19,0,0,0-1.88-2.46,5.82,5.82,0,0,0-3-.8,4.89,4.89,0,0,0-4.56,2.56V97.24h-6.28v3.26h2V109h-2v3.23h9.11V109H131.7v-5.25a4.4,4.4,0,0,1,.69-2.56,2.47,2.47,0,0,1,2.21-1q2.57,0,2.56,3.63v8.41h6.29V109h-2v-5.25a4.47,4.47,0,0,1,.67-2.56,2.42,2.42,0,0,1,2.19-1q2.63,0,2.63,3.63v8.41h6.28Zm9.88-12.07q-4,0-6,2.36a8.41,8.41,0,0,0-2,5.66,7.25,7.25,0,0,0,2.17,5.62,8,8,0,0,0,5.65,2,8.54,8.54,0,0,0,5.94-2.11,7.27,7.27,0,0,0,2.34-5.67,8.21,8.21,0,0,0-2-5.51Q167.13,96.94,163.1,96.94ZM163,109.28a3,3,0,0,1-2.63-1.33,5.68,5.68,0,0,1-.9-3.26,5,5,0,0,1,1-3.28,3.23,3.23,0,0,1,2.61-1.18,3.5,3.5,0,0,1,2.59,1.08,4.56,4.56,0,0,1,1.07,3.31,5.21,5.21,0,0,1-1,3.41A3.33,3.33,0,0,1,163,109.28Zm25-2.3-3.39-.29-.7,2.32H179l8.32-9.54L187,97.24H173.81l-.53,5.25,3.16.34.67-2.36h4.65L173.51,110l.44,2.26h13.13Zm7.62-9.74h-4.46v5.39h4.46Zm0,9.61h-4.46v5.39h4.46Zm13.54-17.49h-4.23l-6.48,22.88h4.22Zm8.68,0h-4.23l-6.45,22.88h4.19Zm15,22.51-.07-2.26a1.22,1.22,0,0,1-.56.1c-.69,0-1-.39-1-1.16v-6.49a4.39,4.39,0,0,0-1.8-3.84,7,7,0,0,0-4.16-1.28,14.55,14.55,0,0,0-3.16.3,24.14,24.14,0,0,0-3.29,1.06l-.56,3.46,3.39.4.5-1.69a2.78,2.78,0,0,1,1.08-.37,11.3,11.3,0,0,1,1.25-.07c1.19,0,1.89.37,2.09,1.1a8.55,8.55,0,0,1,.3,2.26v.5a8.91,8.91,0,0,0-1.18-.11c-.41,0-.81,0-1.21,0a12.64,12.64,0,0,0-4.81.88,3.53,3.53,0,0,0-2.18,3.64,3.66,3.66,0,0,0,1.48,3.33,5.63,5.63,0,0,0,3.11,1,4.67,4.67,0,0,0,3-.91,6.78,6.78,0,0,0,1.8-2,3,3,0,0,0,3.33,3A5.54,5.54,0,0,0,232.85,111.87Zm-9.25-2.32a1.69,1.69,0,0,1-1.36-.52,1.81,1.81,0,0,1-.43-1.21,1.67,1.67,0,0,1,.86-1.68,4.63,4.63,0,0,1,2-.42,7.69,7.69,0,0,1,1.07.07l1.06.13a3.58,3.58,0,0,1-1.08,2.74A3.24,3.24,0,0,1,223.6,109.55Z"></path></g></svg></a></div><ul class="link-list-mdn"><li><a href="https://developer.mozilla.org/en-US/docs/Web">Web Technologies</a></li><li><a href="https://developer.mozilla.org/en-US/docs/Learn">Learn Web Development</a></li><li><a href="https://developer.mozilla.org/en-US/docs/MDN/About">About MDN</a></li><li><a href="https://developer.mozilla.org/en-US/docs/MDN/Feedback">Feedback</a></li></ul><ul class="link-list-moz"><li><a href="https://www.mozilla.org/about/" target="_blank" rel="noopener noreferrer">About</a></li><li><a href="https://shop.spreadshirt.com/mdn-store/" target="_blank" rel="noopener noreferrer">MDN Web Docs Store</a></li><li><a href="https://www.mozilla.org/contact/" target="_blank" rel="noopener noreferrer">Contact Us</a></li><li><a href="https://www.mozilla.org/firefox/?utm_source=developer.mozilla.org&amp;utm_campaign=footer&amp;utm_medium=referral" target="_blank" rel="noopener noreferrer">Firefox</a></li></ul><div class="social social-mdn"><h4>MDN</h4><ul><li><a class="social-icon twitter" href="https://twitter.com/mozdevnet" target="_blank" rel="noopener noreferrer"><span class="visually-hidden">MDN on Twitter</span></a></li><li><a class="social-icon github" href="https://github.com/mdn/" target="_blank" rel="noopener noreferrer"><span class="visually-hidden">MDN on Github</span></a></li></ul></div><div class="social social-moz"><h4>Mozilla</h4><ul><li><a class="social-icon twitter" href="https://twitter.com/mozilla" target="_blank" rel="noopener noreferrer"><span class="visually-hidden">Mozilla on Twitter</span></a></li><li><a class="social-icon instagram" href="https://www.instagram.com/mozillagram/" target="_blank" rel="noopener noreferrer"><span class="visually-hidden">Mozilla on Instagram</span></a></li></ul></div><p id="license" class="footer-license">© 2005-2021 Mozilla and individual contributors. Content is available under <a href="https://developer.mozilla.org/docs/MDN/About#Copyrights_and_licenses">these licenses</a>.</p><ul class="footer-legal"><li><a href="https://www.mozilla.org/about/legal/terms/mozilla" target="_blank" rel="noopener noreferrer">Terms</a></li><li><a href="https://www.mozilla.org/privacy/websites/" target="_blank" rel="noopener noreferrer">Privacy</a></li><li><a href="https://www.mozilla.org/privacy/websites/#cookies" target="_blank" rel="noopener noreferrer">Cookies</a></li></ul></div></footer><div class="page-overlay hidden"></div></div><script type="application/json" id="hydration">{"doc":{"isTranslated":false,"isActive":true,"flaws":{},"title":"Basic concepts behind Web Audio API","mdn_url":"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API","locale":"en-US","native":"English (US)","sidebarHTML":"","body":[{"type":"prose","value":{"id":null,"title":null,"isH3":false,"content":"<div class=\"summary\">\n<p><span class=\"seoSummary\">This article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app.</span> It won't turn you into a master sound engineer, but it will give you enough background to understand why the Web Audio API works like it does.</p>\n</div>"}},{"type":"prose","value":{"id":"Audio_graphs","title":"Audio graphs","isH3":false,"content":"<p>The <a href=\"/en-US/docs/Web/API/Web_Audio_API\">Web Audio API</a> involves handling audio operations inside an <a href=\"/en-US/docs/Web/API/AudioContext\">audio context</a>, and has been designed to allow <strong>modular routing</strong>. Basic audio operations are performed with <strong>audio nodes</strong>, which are linked together to form an <strong>audio routing graph</strong>. Several sources — with different types of channel layout — are supported even within a single context. This modular design provides the flexibility to create complex audio functions with dynamic effects.</p>\n\n<p>Audio nodes are linked via their inputs and outputs, forming a chain that starts with one or more sources, goes through one or more nodes, then ends up at a destination. Although, you don't have to provide a destination if you, say, just want to visualize some audio data. A simple, typical workflow for web audio would look something like this:</p>\n\n<ol>\n <li>Create the audio context.</li>\n <li>Inside the context, create sources — such as <a href=\"/en-US/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a>, oscillator, or stream.</li>\n <li>Create effects nodes, such as reverb, biquad filter, panner, or compressor.</li>\n <li>Choose the final destination for the audio, such as the user's computer speakers.</li>\n <li>Establish connections from the audio sources through zero or more effects, eventually ending at the chosen destination.</li>\n</ol>\n\n<div class=\"notecard note\">\n<h4 id=\"channel_notation\">Channel notation</h4>\n\n<p>The number of audio channels available on a signal is frequently presented in a numeric format, such as 2.0 or 5.1. This is called <a title=\"channel notation\" href=\"https://en.wikipedia.org/wiki/Surround_sound#Channel_notation\" class=\"external\" rel=\" noopener\">channel notation</a>. The first number is the&nbsp;number of full frequency range audio channels that the signal includes. The number after the period indicates the number of those channels which are reserved for low-frequency effect (LFE) outputs; these are often referred to as <strong>subwoofers</strong>.</p>\n</div>\n\n<p><img alt=\"A simple box diagram with an outer box labeled Audio context, and three inner boxes labeled Sources, Effects and Destination. The three inner boxes have arrow between them pointing from left to right, indicating the flow of audio information.\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/webaudioapi_en.svg\" style=\"display: block; margin: 0px auto;\" width=\"643\" height=\"143\" loading=\"lazy\"></p>\n\n<p>Each input or output is composed of one or more audio <strong>channels,</strong> which together represent a specific audio layout. Any discrete channel structure is supported, including <em>mono</em>, <em>stereo</em>, <em>quad</em>, <em>5.1</em>, and so on.</p>\n\n<p><img alt=\"Show the ability of AudioNodes to connect via their inputs and outputs and the channels inside these inputs/outputs.\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/mdn.png\" style=\"display: block; margin: 0px auto;\" width=\"1308\" height=\"750\" loading=\"lazy\"></p>\n\n<p>Audio sources can be obtained in a number of ways:</p>\n\n<ul>\n <li>Sound can be generated directly in JavaScript by an audio node (such as an oscillator).</li>\n <li>Created from raw PCM data (the audio context has methods to decode supported audio formats).</li>\n <li>Taken from HTML media elements (such as <a href=\"/en-US/docs/Web/HTML/Element/video\"><code>&lt;video&gt;</code></a> or <a href=\"/en-US/docs/Web/HTML/Element/audio\"><code>&lt;audio&gt;</code></a>).</li>\n <li>Taken directly from a <a href=\"/en-US/docs/Web/API/WebRTC_API\">WebRTC</a> <a href=\"/en-US/docs/Web/API/MediaStream\"><code>MediaStream</code></a> (such as a webcam or microphone).</li>\n</ul>"}},{"type":"prose","value":{"id":"Audio_data_whats_in_a_sample","title":"Audio data: what's in a sample","isH3":false,"content":"<p>When an audio signal is processed, <strong>sampling</strong> means the conversion of a <a href=\"https://en.wikipedia.org/wiki/Continuous_signal\" title=\"Continuous signal\" class=\"external\" rel=\" noopener\">continuous signal</a> to a <a class=\"mw-redirect external\" href=\"https://en.wikipedia.org/wiki/Discrete_signal\" title=\"Discrete signal\" rel=\" noopener\">discrete signal</a>; or put another way, a continuous sound wave, such as a band playing live, is converted to a sequence of samples (a discrete-time signal) that allow a computer to handle the audio in distinct blocks.</p>\n\n<p>A lot more information can be found on the Wikipedia page <a href=\"https://en.wikipedia.org/wiki/Sampling_%28signal_processing%29\" class=\"external\" rel=\" noopener\">Sampling (signal processing)</a>.</p>"}},{"type":"prose","value":{"id":"Audio_buffers_frames_samples_and_channels","title":"Audio buffers: frames, samples and channels","isH3":false,"content":"<p>An <a href=\"/en-US/docs/Web/API/AudioBuffer\"><code>AudioBuffer</code></a> takes as its parameters a number of channels (1 for mono, 2 for stereo, etc), a length, meaning the number of sample frames inside the buffer, and a sample rate, which is the number of sample frames played per second.</p>\n\n<p>A sample is a single float32 value that represents the value of the audio stream at each specific point in time, in a specific channel (left or right, if in the case of stereo). A frame, or sample frame, is the set of all values for all channels that will play at a specific point in time: all the samples of all the channels that play at the same time (two for a stereo sound, six for 5.1, etc.)</p>\n\n<p>The sample rate is the number of those samples (or frames, since all samples of a frame play at the same time) that will play in one second, measured in Hz. The higher the sample rate, the better the sound quality.</p>\n\n<p>Let's look at a Mono and a Stereo audio buffer, each is one second long, and playing at 44100Hz:</p>\n\n<ul>\n <li>The Mono buffer will have 44100 samples, and 44100 frames. The <code>length</code> property will be 44100.</li>\n <li>The Stereo buffer will have 88200 samples, but still 44100 frames. The <code>length</code> property will still be 44100 since it's equal to the number of frames.</li>\n</ul>\n\n<p><img alt=\"A diagram showing several frames in an audio buffer in a long line, each one containing two samples, as the buffer has two channels, it is stereo.\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/sampleframe-english.png\" width=\"1245\" height=\"219\" loading=\"lazy\"></p>\n\n<p>When a buffer plays, you will hear the left most sample frame, and then the one right next to it, etc. In the case of stereo, you will hear both channels at the same time. Sample frames are very useful, because they are independent of the number of channels, and represent time, in a useful way for doing precise audio manipulation.</p>\n\n<div class=\"note notecard\">\n<p><strong>Note</strong>: To get a time in seconds from a frame count, divide the number of frames by the sample rate. To get a number of frames from a number of samples, divide by the channel count.</p>\n</div>\n\n<p>Here's a couple of simple examples:</p>\n\n<pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">var</span> context <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> buffer <span class=\"token operator\">=</span> context<span class=\"token punctuation\">.</span><span class=\"token function\">createBuffer</span><span class=\"token punctuation\">(</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> <span class=\"token number\">22050</span><span class=\"token punctuation\">,</span> <span class=\"token number\">44100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n\n<div class=\"note notecard\">\n<p><strong>Note</strong>:&nbsp;In&nbsp;<a href=\"https://en.wikipedia.org/wiki/Digital_audio\" title=\"Digital audio\" class=\"external\" rel=\" noopener\">digital audio</a>,&nbsp;<strong>44,100&nbsp;<a href=\"https://en.wikipedia.org/wiki/Hertz\" class=\"external\" rel=\" noopener\">Hz</a></strong>&nbsp;(alternately represented as&nbsp;<strong>44.1&nbsp;kHz</strong>) is a common&nbsp;<a href=\"https://en.wikipedia.org/wiki/Sampling_frequency\" title=\"Sampling frequency\" class=\"external\" rel=\" noopener\">sampling frequency</a>. Why 44.1kHz?&nbsp;<br>\n <br>\n Firstly, because the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Hearing_range\" title=\"Hearing range\" class=\"external\" rel=\" noopener\">hearing range</a>&nbsp;of human ears is roughly 20&nbsp;Hz to 20,000&nbsp;Hz. Via the&nbsp;<a href=\"https://en.wikipedia.org/wiki/Nyquist%E2%80%93Shannon_sampling_theorem\" title=\"Nyquist–Shannon sampling theorem\" class=\"external\" rel=\" noopener\">Nyquist–Shannon sampling theorem</a>, the sampling frequency must be greater than twice the maximum frequency one wishes to reproduce. Therefore, the sampling rate has to be greater than 40&nbsp;kHz.<br>\n <br>\n Secondly, signals must be&nbsp;<a href=\"https://en.wikipedia.org/wiki/Low-pass_filter\" title=\"Low-pass filter\" class=\"external\" rel=\" noopener\">low-pass filtered</a>&nbsp;before sampling, otherwise <a href=\"https://en.wikipedia.org/wiki/Aliasing\" class=\"external\" rel=\" noopener\">aliasing</a>&nbsp;occurs. While an ideal low-pass filter would perfectly pass frequencies below 20&nbsp;kHz (without attenuating them) and perfectly cut off frequencies above 20&nbsp;kHz, in practice a&nbsp;<a href=\"https://en.wikipedia.org/wiki/Transition_band\" title=\"Transition band\" class=\"external\" rel=\" noopener\">transition band</a>&nbsp;is necessary, where frequencies are partly attenuated. The wider this transition band is, the easier and more economical it is to make an&nbsp;<a href=\"https://en.wikipedia.org/wiki/Anti-aliasing_filter\" title=\"Anti-aliasing filter\" class=\"external\" rel=\" noopener\">anti-aliasing filter</a>. The 44.1&nbsp;kHz sampling frequency allows for a 2.05&nbsp;kHz transition band.</p>\n</div>\n\n<p>If you use this call above, you will get a stereo buffer with two channels, that when played back on an AudioContext running at 44100Hz (very common, most normal sound cards run at this rate), will last for 0.5 seconds: 22050 frames/44100Hz = 0.5 seconds.</p>\n\n<pre class=\"brush: js notranslate\"><code><span class=\"token keyword\">var</span> context <span class=\"token operator\">=</span> <span class=\"token keyword\">new</span> <span class=\"token class-name\">AudioContext</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token keyword\">var</span> buffer <span class=\"token operator\">=</span> context<span class=\"token punctuation\">.</span><span class=\"token function\">createBuffer</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> <span class=\"token number\">22050</span><span class=\"token punctuation\">,</span> <span class=\"token number\">22050</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n\n<p>If you use this call, you will get a mono buffer with just one channel), that when played back on an AudioContext running at 44100Hz, will be automatically <em>resampled</em> to 44100Hz (and therefore yield 44100 frames), and last for 1.0 second: 44100 frames/44100Hz = 1 second.</p>\n\n<div class=\"note notecard\">\n<p><strong>Note</strong>: audio resampling is very similar to image resizing. Say you've got a 16 x 16 image, but you want it to fill a 32x32 area. You resize (or resample) it. The result has less quality (it can be blurry or edgy, depending on the resizing algorithm), but it works, with the resized image taking up less space. Resampled audio is exactly the same: you save space, but in practice you will be unable to properly reproduce high frequency content, or treble sound.</p>\n</div>"}},{"type":"prose","value":{"id":"Planar_versus_interleaved_buffers","title":"Planar versus interleaved buffers","isH3":true,"content":"<p>The Web Audio API uses a planar buffer format. The left and right channels are stored like this:</p>\n\n<pre class=\"notranslate\">LLLLLLLLLLLLLLLLRRRRRRRRRRRRRRRR (for a buffer of 16 frames)</pre>\n\n<p>This is very common in audio processing: it makes it easy to process each channel independently.</p>\n\n<p>The alternative is to use an interleaved buffer format:</p>\n\n<pre class=\"notranslate\">LRLRLRLRLRLRLRLRLRLRLRLRLRLRLRLR (for a buffer of 16 frames)</pre>\n\n<p>This format is very common for storing and playing back audio without much processing, for example a decoded MP3 stream.<br>\n <br>\n The Web Audio API exposes <strong>only</strong> planar buffers, because it's made for processing. It works with planar, but converts the audio to interleaved when it is sent to the sound card for playback. Conversely, when an MP3 is decoded, it starts off in interleaved format, but is converted to planar for processing.</p>"}},{"type":"prose","value":{"id":"Audio_channels","title":"Audio channels","isH3":false,"content":"<p>Different audio buffers contain different numbers of channels: from the more basic mono (only one channel) and stereo (left and right channels), to more complex sets like quad and 5.1, which have different sound samples contained in each channel, leading to a richer sound experience. The channels are usually represented by standard abbreviations detailed in the table below:</p>\n\n<table class=\"standard-table\">\n <tbody>\n  <tr>\n   <td><em>Mono</em></td>\n   <td><code>0: M: mono</code></td>\n  </tr>\n  <tr>\n   <td><em>Stereo</em></td>\n   <td><code>0: L: left<br>\n    1: R: right</code></td>\n  </tr>\n  <tr>\n   <td><em>Quad</em></td>\n   <td><code>0: L: left<br>\n    1: R: right<br>\n    2: SL: surround left<br>\n    3: SR: surround right</code></td>\n  </tr>\n  <tr>\n   <td><em>5.1</em></td>\n   <td><code>0: L: left<br>\n    1: R: right<br>\n    2: C: center<br>\n    3: LFE: subwoofer<br>\n    4: SL: surround left<br>\n    5: SR: surround right</code></td>\n  </tr>\n </tbody>\n</table>"}},{"type":"prose","value":{"id":"Up-mixing_and_down-mixing","title":"Up-mixing and down-mixing","isH3":true,"content":"<p>When the number of channels doesn't match between an input and an output, up- or down-mixing happens according the following rules. This can be somewhat controlled by setting the <a href=\"/en-US/docs/Web/API/AudioNode/channelInterpretation\"><code>AudioNode.channelInterpretation</code></a> property to <code>speakers</code> or <code>discrete</code>:</p>\n\n<table class=\"standard-table\">\n <thead>\n  <tr>\n   <th scope=\"row\">Interpretation</th>\n   <th scope=\"col\">Input channels</th>\n   <th scope=\"col\">Output channels</th>\n   <th scope=\"col\">Mixing rules</th>\n  </tr>\n </thead>\n <tbody>\n  <tr>\n   <th rowspan=\"13\" scope=\"row\"><code>speakers</code></th>\n   <td><code>1</code> <em>(Mono)</em></td>\n   <td><code>2</code> <em>(Stereo)</em></td>\n   <td><em>Up-mix from mono to stereo</em>.<br>\n    The <code>M</code> input channel is used for both output channels (<code>L</code> and <code>R</code>).<br>\n    <code>output.L = input.M<br>\n    output.R = input.M</code></td>\n  </tr>\n  <tr>\n   <td><code>1</code> <em>(Mono)</em></td>\n   <td><code>4</code> <em>(Quad)</em></td>\n   <td><em>Up-mix from mono to quad.</em><br>\n    The <code>M</code> input channel is used for non-surround output channels (<code>L</code> and <code>R</code>). Surround output channels (<code>SL</code> and <code>SR</code>) are silent.<br>\n    <code>output.L = input.M<br>\n    output.R = input.M<br>\n    output.SL = 0<br>\n    output.SR = 0</code></td>\n  </tr>\n  <tr>\n   <td><code>1</code> <em>(Mono)</em></td>\n   <td><code>6</code> <em>(5.1)</em></td>\n   <td><em>Up-mix from mono to 5.1.</em><br>\n    The <code>M</code> input channel is used for the center output channel (<code>C</code>). All the others (<code>L</code>, <code>R</code>, <code>LFE</code>, <code>SL</code>, and <code>SR</code>) are silent.<br>\n    <code>output.L = 0<br>\n    output.R = 0</code><br>\n    <code>output.C = input.M<br>\n    output.LFE = 0<br>\n    output.SL = 0<br>\n    output.SR = 0</code></td>\n  </tr>\n  <tr>\n   <td><code>2</code> <em>(Stereo)</em></td>\n   <td><code>1</code> <em>(Mono)</em></td>\n   <td><em>Down-mix from stereo to mono</em>.<br>\n    Both input channels (<code>L</code> and <code>R</code>) are equally combined to produce the unique output channel (<code>M</code>).<br>\n    <code>output.M = 0.5 * (input.L + input.R)</code></td>\n  </tr>\n  <tr>\n   <td><code>2</code> <em>(Stereo)</em></td>\n   <td><code>4</code> <em>(Quad)</em></td>\n   <td><em>Up-mix from stereo to quad.</em><br>\n    The <code>L</code> and <code>R </code>input channels are used for their non-surround respective output channels (<code>L</code> and <code>R</code>). Surround output channels (<code>SL</code> and <code>SR</code>) are silent.<br>\n    <code>output.L = input.L<br>\n    output.R = input.R<br>\n    output.SL = 0<br>\n    output.SR = 0</code></td>\n  </tr>\n  <tr>\n   <td><code>2</code> <em>(Stereo)</em></td>\n   <td><code>6</code> <em>(5.1)</em></td>\n   <td><em>Up-mix from stereo to 5.1.</em><br>\n    The <code>L</code> and <code>R </code>input channels are used for their non-surround respective output channels (<code>L</code> and <code>R</code>). Surround output channels (<code>SL</code> and <code>SR</code>), as well as the center (<code>C</code>) and subwoofer (<code>LFE</code>) channels, are left silent.<br>\n    <code>output.L = input.L<br>\n    output.R = input.R<br>\n    output.C = 0<br>\n    output.LFE = 0<br>\n    output.SL = 0<br>\n    output.SR = 0</code></td>\n  </tr>\n  <tr>\n   <td><code>4</code> <em>(Quad)</em></td>\n   <td><code>1</code> <em>(Mono)</em></td>\n   <td><em>Down-mix from quad to mono</em>.<br>\n    All four input channels (<code>L</code>, <code>R</code>, <code>SL</code>, and <code>SR</code>) are equally combined to produce the unique output channel (<code>M</code>).<br>\n    <code>output.M = 0.25 * (input.L + input.R + </code><code>input.SL + input.SR</code><code>)</code></td>\n  </tr>\n  <tr>\n   <td><code>4</code> <em>(Quad)</em></td>\n   <td><code>2</code> <em>(Stereo)</em></td>\n   <td><em>Down-mix from quad to stereo</em>.<br>\n    Both left input channels (<code>L</code> and <code>SL</code>) are equally combined to produce the unique left output channel (<code>L</code>). And similarly, both right input channels (<code>R</code> and <code>SR</code>) are equally combined to produce the unique right output channel (<code>R</code>).<br>\n    <code>output.L = 0.5 * (input.L + input.SL</code><code>)</code><br>\n    <code>output.R = 0.5 * (input.R + input.SR</code><code>)</code></td>\n  </tr>\n  <tr>\n   <td><code>4</code> <em>(Quad)</em></td>\n   <td><code>6</code> <em>(5.1)</em></td>\n   <td><em>Up-mix from quad to 5.1.</em><br>\n    The <code>L</code>, <code>R</code>, <code>SL</code>, and <code>SR</code> input channels are used for their respective output channels (<code>L</code> and <code>R</code>). Center (<code>C</code>) and subwoofer (<code>LFE</code>) channels are left silent.<br>\n    <code>output.L = input.L<br>\n    output.R = input.R<br>\n    output.C = 0<br>\n    output.LFE = 0<br>\n    output.SL = input.SL<br>\n    output.SR = input.SR</code></td>\n  </tr>\n  <tr>\n   <td><code>6</code> <em>(5.1)</em></td>\n   <td><code>1</code> <em>(Mono)</em></td>\n   <td><em>Down-mix from 5.1 to mono.</em><br>\n    The left (<code>L</code> and <code>SL</code>), right (<code>R</code> and <code>SR</code>) and central channels are all mixed together. The surround channels are slightly attenuated and the regular lateral channels are power-compensated to make them count as a single channel by multiplying by <code>√2/2</code>. The subwoofer (<code>LFE</code>) channel is lost.<br>\n    <code>output.M = 0.7071 * (input.L + input.R) + input.C + 0.5 * (input.SL + input.SR)</code></td>\n  </tr>\n  <tr>\n   <td><code>6</code> <em>(5.1)</em></td>\n   <td><code>2</code> <em>(Stereo)</em></td>\n   <td><em>Down-mix from 5.1 to stereo.</em><br>\n    The central channel (<code>C</code>) is summed with each lateral surround channel (<code>SL</code> or <code>SR</code>) and mixed to each lateral channel. As it is mixed down to two channels, it is mixed at a lower power: in each case it is multiplied by <code>√2/2</code>. The subwoofer (<code>LFE</code>) channel is lost.<br>\n    <code>output.L = input.L + 0.7071 * (input.C + input.SL)<br>\n    output.R = input.R </code><code>+ 0.7071 * (input.C + input.SR)</code></td>\n  </tr>\n  <tr>\n   <td><code>6</code> <em>(5.1)</em></td>\n   <td><code>4</code> <em>(Quad)</em></td>\n   <td><em>Down-mix from 5.1 to quad.</em><br>\n    The central (<code>C</code>) is mixed with the lateral non-surround channels (<code>L</code> and <code>R</code>). As it is mixed down to two channels, it is mixed at a lower power: in each case it is multiplied by <code>√2/2</code>. The surround channels are passed unchanged. The subwoofer (<code>LFE</code>) channel is lost.<br>\n    <code>output.L = input.L + 0.7071 * input.C<br>\n    output.R = input.R + 0.7071 * input.C<br>\n    output.SL = input.SL<br>\n    output.SR = input.SR</code></td>\n  </tr>\n  <tr>\n   <td colspan=\"2\">Other, non-standard layouts</td>\n   <td>Non-standard channel layouts are handled as if <code>channelInterpretation</code> is set to <code>discrete</code>.<br>\n    The specification explicitly allows the future definition of new speaker layouts. This fallback is therefore not future proof as the behavior of the browsers for a specific number of channels may change in the future.</td>\n  </tr>\n  <tr>\n   <th rowspan=\"2\" scope=\"row\"><code>discrete</code></th>\n   <td>any (<code>x</code>)</td>\n   <td>any (<code>y</code>) where <code>x&lt;y</code></td>\n   <td><em>Up-mix discrete channels.</em><br>\n    Fill each output channel with its input counterpart, that is the input channel with the same index. Channels with no corresponding input channels are left silent.</td>\n  </tr>\n  <tr>\n   <td>any (<code>x</code>)</td>\n   <td>any (<code>y</code>) where <code>x&gt;y</code></td>\n   <td><em>Down-mix discrete channels.</em><br>\n    Fill each output channel with its input counterpart, that is the input channel with the same index. Input channels with no corresponding output channels are dropped.</td>\n  </tr>\n </tbody>\n</table>"}},{"type":"prose","value":{"id":"Visualizations","title":"Visualizations","isH3":false,"content":"<p>In general, audio visualizations are achieved by accessing an output of audio data over time, usually gain or frequency data, and then using a graphical technology to turn that into a visual output, such as a graph. The Web Audio API has an <a href=\"/en-US/docs/Web/API/AnalyserNode\"><code>AnalyserNode</code></a> available that doesn't alter the audio signal passing through it. Instead it outputs audio data that can be passed to a visualization technology such as <a href=\"/en-US/docs/Web/HTML/Element/canvas\"><code>&lt;canvas&gt;</code></a>.</p>\n\n<p><img alt=\"Without modifying the audio stream, the node allows to get the frequency and time-domain data associated to it, using a FFT.\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/fttaudiodata_en.svg\" width=\"693\" height=\"206\" loading=\"lazy\"></p>\n\n<p>You can grab data using the following methods:</p>\n\n<dl>\n <dt><a href=\"/en-US/docs/Web/API/AnalyserNode/getFloatFrequencyData\"><code>AnalyserNode.getFloatFrequencyData()</code></a></dt>\n <dd>Copies the current frequency data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array\"><code>Float32Array</code></a> array passed into it.</dd>\n <dt><a href=\"/en-US/docs/Web/API/AnalyserNode/getByteFrequencyData\"><code>AnalyserNode.getByteFrequencyData()</code></a></dt>\n <dd>Copies the current frequency data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array\"><code>Uint8Array</code></a> (unsigned byte array) passed into it.</dd>\n <dt><a href=\"/en-US/docs/Web/API/AnalyserNode/getFloatTimeDomainData\"><code>AnalyserNode.getFloatTimeDomainData()</code></a></dt>\n <dd>Copies the current waveform, or time-domain, data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Float32Array\"><code>Float32Array</code></a> array passed into it.</dd>\n <dt><a href=\"/en-US/docs/Web/API/AnalyserNode/getByteTimeDomainData\"><code>AnalyserNode.getByteTimeDomainData()</code></a></dt>\n <dd>Copies the current waveform, or time-domain, data into a <a href=\"/en-US/docs/Web/JavaScript/Reference/Global_Objects/Uint8Array\"><code>Uint8Array</code></a> (unsigned byte array) passed into it.</dd>\n</dl>\n\n<div class=\"note notecard\">\n<p><strong>Note</strong>: For more information, see our <a href=\"/en-US/docs/Web/API/Web_Audio_API/Visualizations_with_Web_Audio_API\">Visualizations with Web Audio API</a> article.</p>\n</div>"}},{"type":"prose","value":{"id":"Spatialisations","title":"Spatialisations","isH3":false,"content":"<div>\n<p>An audio spatialisation (handled by the <a href=\"/en-US/docs/Web/API/PannerNode\"><code>PannerNode</code></a> and <a href=\"/en-US/docs/Web/API/AudioListener\"><code>AudioListener</code></a> nodes in the Web Audio API) allows us to model the position and behavior of an audio signal at a certain point in space, and the listener hearing that audio.</p>\n\n<p>The panner's position is described with right-hand Cartesian coordinates; its movement using a velocity vector, necessary for creating Doppler effects, and its directionality using a directionality cone.The cone can be very large, e.g. for omnidirectional sources.</p>\n</div>\n\n<p><img alt=\"The PannerNode brings a spatial position and velocity and a directionality for a given signal.\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/pannernode_en.svg\" width=\"799\" height=\"340\" loading=\"lazy\"></p>\n\n<div>\n<p>The listener's position is described using right-hand Cartesian coordinates; its movement using a velocity vector and the direction the listener's head is pointing using two direction vectors: up and front. These respectively define the direction of the top of the listener's head, and the direction the listener's nose is pointing, and are at right angles to one another.</p>\n</div>\n\n<p><img alt=\"We see the position, up and front vectors of an AudioListener, with the up and front vectors at 90° from the other.\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/webaudiolistenerreduced.png\" style=\"display: block; margin: 0 auto;\" width=\"634\" height=\"250\" loading=\"lazy\"></p>\n\n<div class=\"note notecard\">\n<p><strong>Note</strong>: For more information, see our <a href=\"/en-US/docs/Web/API/Web_Audio_API/Web_audio_spatialization_basics\">Web audio spatialization basics</a> article.</p>\n</div>"}},{"type":"prose","value":{"id":"Fan-in_and_Fan-out","title":"Fan-in and Fan-out","isH3":false,"content":"<p>In audio terms, <strong>fan-in</strong> describes the process by which a <a href=\"/en-US/docs/Web/API/ChannelMergerNode\"><code>ChannelMergerNode</code></a> takes a series of mono input sources and outputs a single multi-channel signal:</p>\n\n<p><img alt=\"\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/fanin.svg\" width=\"325\" height=\"258\" loading=\"lazy\"></p>\n\n<p><strong>Fan-out</strong> describes the opposite process, whereby a <a href=\"/en-US/docs/Web/API/ChannelSplitterNode\"><code>ChannelSplitterNode</code></a> takes a multi-channel input source and outputs multiple mono output signals:</p>\n\n<p><img alt=\"\" src=\"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API/fanout.svg\" width=\"325\" height=\"258\" loading=\"lazy\"></p>"}}],"toc":[{"text":"Audio graphs","id":"Audio_graphs"},{"text":"Audio data: what's in a sample","id":"Audio_data_whats_in_a_sample"},{"text":"Audio buffers: frames, samples and channels","id":"Audio_buffers_frames_samples_and_channels"},{"text":"Audio channels","id":"Audio_channels"},{"text":"Visualizations","id":"Visualizations"},{"text":"Spatialisations","id":"Spatialisations"},{"text":"Fan-in and Fan-out","id":"Fan-in_and_Fan-out"}],"summary":"\nThis article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app. It won't turn you into a master sound engineer, but it will give you enough background to understand why the Web Audio API works like it does.\nThis article explains some of the audio theory behind how the features of the Web Audio API work, to help you make informed decisions while designing how audio is routed through your app.","popularity":0.0016,"modified":"2021-05-28T04:40:33.000Z","other_translations":[{"title":"Les concepts de base de la Web Audio API","locale":"fr","native":"Français"},{"title":"Basic concepts behind Web Audio API","locale":"ja","native":"日本語"},{"title":"Basic concepts behind Web Audio API","locale":"ko","native":"한국어"},{"title":"网页音频接口的基本概念","locale":"zh-CN","native":"中文 (简体)"}],"source":{"folder":"en-us/web/api/web_audio_api/basic_concepts_behind_web_audio_api","github_url":"https://github.com/mdn/content/blob/main/files/en-us/web/api/web_audio_api/basic_concepts_behind_web_audio_api/index.html","last_commit_url":"https://github.com/mdn/content/commit/d9c4fbb8634df27ca295ec25089a5f7302afb3bf","filename":"index.html"},"parents":[{"uri":"/en-US/docs/Web","title":"Web technology for developers"},{"uri":"/en-US/docs/Web/API","title":"Web APIs"},{"uri":"/en-US/docs/Web/API/Web_Audio_API","title":"Web Audio API"},{"uri":"/en-US/docs/Web/API/Web_Audio_API/Basic_concepts_behind_Web_Audio_API","title":"Basic concepts behind Web Audio API"}],"pageTitle":"Basic concepts behind Web Audio API - Web APIs | MDN","noIndexing":false}}</script><form id="gclp-frame-form" target="gclp-frame" method="post" style="display: none;"></form><div class="gclp-code-grabber" data-gclp-id="0" style="left: 1312.73px; top: 3253.56px; display: none;" data-hasqtip="true"></div><div class="gclp-code-grabber" data-gclp-id="1" style="left: 1312.73px; top: 3855.8px; display: none;" data-hasqtip="true"></div><div class="gclp-code-grabber" data-gclp-id="2" style="left: 1312.73px; top: 4368.64px; display: none;" data-hasqtip="true"></div><div class="gclp-code-grabber" data-gclp-id="3" style="left: 1312.73px; top: 4565.66px; display: none;" data-hasqtip="true"></div><span style="margin: 0px auto; border: 2px dotted rgb(0, 0, 0); position: absolute; z-index: 2147483647; visibility: hidden; left: 1038px; width: 0px; top: 3516px; height: 0px;"></span><span style="z-index: 2147483647; position: absolute; visibility: hidden; left: 1023px; width: 50px; top: 3501px; height: 20px; font-size: 10px; color: black;"></span></body></html>